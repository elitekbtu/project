#!/usr/bin/env python3
"""
Catalog Processing Tasks

Celery –∑–∞–¥–∞—á–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤:
- –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- –ò–ò –∞–Ω–∞–ª–∏–∑ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
- –ò–º–ø–æ—Ä—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
- –¶–µ–ø–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–∞—Ä—Å–∏–Ω–≥ -> –∞–Ω–∞–ª–∏–∑ -> –∏–º–ø–æ—Ä—Ç)
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from celery import Task, chain, group, chord
from celery.exceptions import Retry

from celery_app import celery_app
from app.agents.parser_agent import EnhancedLamodaParser, ParsedProduct
from app.agents.catalog_agent import CatalogAgent

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CallbackTask(Task):
    """–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–∞—á–∞ —Å callback'–∞–º–∏"""
    
    def on_success(self, retval, task_id, args, kwargs):
        """Callback –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏"""
        logger.info(f"‚úÖ Task {task_id} completed successfully")
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """Callback –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        logger.error(f"‚ùå Task {task_id} failed: {exc}")
    
    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """Callback –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ"""
        logger.warning(f"üîÑ Task {task_id} retrying: {exc}")

@celery_app.task(bind=True, base=CallbackTask, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3, 'countdown': 60})
def parse_catalog_task(self, query: str, limit: int = 20, domain: str = "kz") -> Dict[str, Any]:
    """
    –ó–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ç–∞–ª–æ–≥–∞
    
    Args:
        query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        domain: –¥–æ–º–µ–Ω –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (ru, kz, by)
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
    """
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–¥–∞—á–∏
    self.update_state(state='PROGRESS', meta={'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞...', 'progress': 0})
    
    async def run_parsing():
        parser = None
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
            parser = EnhancedLamodaParser(domain=domain)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥
            logger.info(f"Starting parsing with query: {query}, limit: {limit}, domain: {domain}")
            products = await parser.parse_catalog(query, limit=limit, page=1)
            
            self.update_state(
                state='PROGRESS',
                meta={
                    'status': '–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞...',
                    'progress': 80,
                    'products_found': len(products)
                }
            )
            
            # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —á–µ—Ä–µ–∑ Celery
            serialized_products = []
            for product in products:
                product_dict = {
                    'sku': product.sku,
                    'name': product.name,
                    'brand': product.brand,
                    'price': product.price,
                    'old_price': product.old_price,
                    'url': product.url,
                    'image_url': product.image_url,
                    'image_urls': product.image_urls,
                    'description': product.description,
                    'category': product.category,
                    'clothing_type': product.clothing_type,
                    'color': product.color,
                    'sizes': product.sizes,
                    'style': product.style,
                    'collection': product.collection,
                    'rating': product.rating,
                    'reviews_count': product.reviews_count,
                    'parse_quality': product.parse_quality,
                    'parse_metadata': product.parse_metadata,
                    'parsed_at': product.parsed_at.isoformat()
                }
                serialized_products.append(product_dict)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            total_quality = sum(p.parse_quality for p in products)
            quality_score = total_quality / len(products) if products else 0.0
            
            return {
                'success': True,
                'products': serialized_products,
                'total_found': len(products),
                'success_count': len(products),
                'failed_count': 0,
                'quality_score': quality_score,
                'parsing_time': 0.0,  # –í—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ
                'metadata': {
                    'query': query,
                    'domain': domain,
                    'limit': limit
                },
                'task_completed_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Parsing task failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__,
                'task_failed_at': datetime.now().isoformat()
            }
        finally:
            if parser:
                await parser.close()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(run_parsing())
        loop.close()
        
        # –ù–ï –æ–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ - –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        # Celery –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ SUCCESS –ø—Ä–∏ –≤–æ–∑–≤—Ä–∞—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        return result
        
    except Exception as e:
        logger.error(f"Failed to run parsing task: {e}")
        self.update_state(
            state='FAILURE',
            meta={'status': f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}', 'progress': 0}
        )
        raise

@celery_app.task(bind=True, base=CallbackTask, autoretry_for=(Exception,), retry_kwargs={'max_retries': 2, 'countdown': 30})
def import_to_catalog_task(self, parsing_result: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ó–∞–¥–∞—á–∞ –∏–º–ø–æ—Ä—Ç–∞ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–∞–ª–æ–≥
    
    Args:
        parsing_result: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–º–ø–æ—Ä—Ç–∞
    """
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–¥–∞—á–∏
    if not parsing_result.get('success', False):
        logger.error("Cannot import products: parsing task failed")
        return {
            'success': False,
            'error': 'Parsing task failed',
            'skipped': True
        }
    
    products_data = parsing_result.get('products', [])
    if not products_data:
        logger.warning("No products to import")
        return {
            'success': True,
            'imported_count': 0,
            'skipped': True,
            'reason': 'no_products'
        }
    
    self.update_state(
        state='PROGRESS',
        meta={
            'status': '–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –∫–∞—Ç–∞–ª–æ–≥–∞...',
            'progress': 0,
            'products_count': len(products_data)
        }
    )
    
    async def run_import():
        agent = None
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç –∫–∞—Ç–∞–ª–æ–≥–∞
            agent = CatalogAgent(upload_dir="uploads/items")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ ParsedProduct –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
            products = []
            
            for product_data in products_data:
                try:
                    # –°–æ–∑–¥–∞–µ–º ParsedProduct –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                    product = ParsedProduct(
                        sku=product_data['sku'],
                        name=product_data['name'],
                        brand=product_data['brand'],
                        price=product_data['price'],
                        old_price=product_data.get('old_price'),
                        url=product_data.get('url', ''),
                        image_url=product_data.get('image_url', ''),
                        image_urls=product_data.get('image_urls', []),
                        description=product_data.get('description'),
                        category=product_data.get('category'),
                        clothing_type=product_data.get('clothing_type'),
                        color=product_data.get('color'),
                        sizes=product_data.get('sizes', []),
                        style=product_data.get('style'),
                        collection=product_data.get('collection'),
                        rating=product_data.get('rating'),
                        reviews_count=product_data.get('reviews_count'),
                        parse_quality=product_data.get('parse_quality', 0.0),
                        parse_metadata=product_data.get('parse_metadata', {}),
                        parsed_at=datetime.fromisoformat(product_data['parsed_at'])
                    )
                    products.append(product)
                except Exception as e:
                    logger.error(f"Failed to convert product data: {e}")
                    continue
            
            self.update_state(
                state='PROGRESS',
                meta={
                    'status': '–ò–º–ø–æ—Ä—Ç —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–∞–ª–æ–≥...',
                    'progress': 30,
                    'products_to_import': len(products)
                }
            )
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–º–ø–æ—Ä—Ç
            result = await agent.import_parsed_products_to_catalog(products)
            
            return {
                'success': True,
                'imported_count': result.imported_count,
                'updated_count': result.updated_count,
                'skipped_count': result.skipped_count,
                'error_count': result.error_count,
                'total_processed': result.total_processed,
                'import_time': result.import_time,
                'errors': result.errors,
                'warnings': result.warnings,
                'metadata': result.metadata,
                'task_completed_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Import task failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__,
                'task_failed_at': datetime.now().isoformat()
            }
        finally:
            if agent:
                await agent.close()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–º–ø–æ—Ä—Ç
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(run_import())
        loop.close()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if result['success']:
            self.update_state(
                state='SUCCESS',
                meta={
                    'status': '–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ',
                    'progress': 100,
                    'imported_count': result.get('imported_count', 0),
                    'updated_count': result.get('updated_count', 0)
                }
            )
        
        return result
        
    except Exception as e:
        logger.error(f"Failed to run import task: {e}")
        self.update_state(
            state='FAILURE',
            meta={'status': f'–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {str(e)}', 'progress': 0}
        )
        raise

@celery_app.task(bind=True, base=CallbackTask)
def process_catalog_chain(self, query: str, limit: int = 20, domain: str = "kz") -> Dict[str, Any]:
    """
    –ì–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ - —Ü–µ–ø–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–∞–ª–æ–≥–∞
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—É—é —Ü–µ–ø–æ—á–∫—É: –ü–∞—Ä—Å–∏–Ω–≥ -> –ò–º–ø–æ—Ä—Ç –≤ –ë–î
    
    Args:
        query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        limit: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
        domain: –¥–æ–º–µ–Ω –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞  
    
    Returns:
        Dict —Å –ø–æ–ª–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ü–µ–ø–æ—á–∫–∏
    """
    
    self.update_state(
        state='PROGRESS',
        meta={
            'status': '–ó–∞–ø—É—Å–∫ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞—Ç–∞–ª–æ–≥–∞',
            'progress': 0,
            'chain_step': 'initialization',
            'query': query,
            'limit': limit,
            'domain': domain
        }
    )
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É –∑–∞–¥–∞—á
        processing_chain = chain(
            parse_catalog_task.s(query, limit, domain),
            import_to_catalog_task.s()
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–µ–ø–æ—á–∫—É –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        chain_result = processing_chain.apply_async()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–µ
        report = {
            'success': True,
            'chain_started_at': datetime.now().isoformat(),
            'chain_task_id': chain_result.id,
            'query': query,
            'limit': limit,
            'domain': domain,
            'status': 'Chain started successfully',
            'message': 'Use chain_task_id to track progress'
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.update_state(
            state='SUCCESS',
            meta={
                'status': '–¶–µ–ø–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—É—â–µ–Ω–∞',
                'progress': 100,
                'chain_step': 'started',
                'chain_task_id': chain_result.id
            }
        )
        
        return report
        
    except Exception as e:
        logger.error(f"Catalog processing chain failed: {e}")
        
        error_result = {
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__,
            'chain_failed_at': datetime.now().isoformat(),
            'query': query,
            'limit': limit,
            'domain': domain
        }
        
        self.update_state(
            state='FAILURE',
            meta={
                'status': f'–¶–µ–ø–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å: {str(e)}',
                'progress': 0,
                'chain_step': 'failed'
            }
        )
        
        return error_result

@celery_app.task(bind=True, base=CallbackTask)
def get_catalog_statistics(self) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞—Ç–∞–ª–æ–≥–∞
    
    Returns:
        Dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∫–∞—Ç–∞–ª–æ–≥–∞
    """
    
    try:
        from app.core.database import SessionLocal
        from app.db.models.item import Item
        from sqlalchemy import func
        
        db = SessionLocal()
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_items = db.query(Item).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º
        brand_stats = db.query(Item.brand, func.count(Item.id)).group_by(Item.brand).all()
        top_brands = [{'brand': brand, 'count': count} for brand, count in brand_stats[:10]]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_stats = db.query(Item.category, func.count(Item.id)).group_by(Item.category).all()
        top_categories = [{'category': category, 'count': count} for category, count in category_stats[:10]]
        
        # –¶–µ–Ω–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        price_stats = db.query(
            func.min(Item.price),
            func.max(Item.price), 
            func.avg(Item.price)
        ).first()
        
        # –ù–µ–¥–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
        recent_date = datetime.now() - timedelta(days=7)
        recent_items = db.query(Item).filter(Item.created_at >= recent_date).count()
        
        db.close()
        
        return {
            'success': True,
            'statistics': {
                'total_items': total_items,
                'recent_items_week': recent_items,
                'price_range': {
                    'min': float(price_stats[0]) if price_stats[0] else 0,
                    'max': float(price_stats[1]) if price_stats[1] else 0,
                    'average': float(price_stats[2]) if price_stats[2] else 0
                },
                'top_brands': top_brands,
                'top_categories': top_categories
            },
            'generated_at': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get catalog statistics: {e}")
        return {
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }

# –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
@celery_app.task
def cleanup_old_cache():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞"""
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞
    logger.info("Cache cleanup completed")
    return {'success': True, 'cleanup_completed_at': datetime.now().isoformat()} 